{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Patient's data preprocessing and preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = os.path.join(os.getcwd(), 'dataset')\n",
    "cancer_dir = os.path.join(data_dir, 'cancer')\n",
    "fibro_dir = os.path.join(data_dir, 'fibro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "    \n",
    "def classdir_prepare(class_pathlist, class_destdir, class_name='Class None'):\n",
    "    if os.path.exists(class_destdir):\n",
    "        shutil.rmtree(class_destdir)\n",
    "    os.makedirs(class_destdir)\n",
    "    for fname in tqdm(class_pathlist, ascii=True, desc=class_name):\n",
    "        if not os.path.exists(fname):\n",
    "            continue\n",
    "        shutil.copyfile(fname, os.path.join(class_destdir, os.path.basename(fname)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Telegram notifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import telepot\n",
    "\n",
    "bot_token = '305845736:AAFEWvma4up5MgyvioxLr8lKJWqbCYstUf4'\n",
    "user_id = 77680768\n",
    "\n",
    "telebot = telepot.Bot(bot_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning with ConvNets using Keras framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras backend: tensorflow\n",
      "Keras image format: channels_last \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as KBackend\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, ZeroPadding2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "from keras.models import model_from_json\n",
    "from keras.callbacks import Callback, ModelCheckpoint, TensorBoard\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "print('Keras backend:', KBackend.backend())\n",
    "print('Keras image format:', KBackend.image_data_format(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 27297\n",
    "np.random_seed = 27297\n",
    "batch_size = 16\n",
    "\n",
    "train_data_generator = ImageDataGenerator(horizontal_flip=True, \n",
    "                                          vertical_flip=True, \n",
    "                                          rotation_range=90,\n",
    "                                          fill_mode='nearest')\n",
    "test_data_generator = ImageDataGenerator()\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_seed)\n",
    "\n",
    "cancer_list = np.array([os.path.join(cancer_dir, x) for x in os.listdir(cancer_dir)])\n",
    "fibro_list = np.array([os.path.join(fibro_dir, x) for x in os.listdir(fibro_dir)])\n",
    "cancer_list = cancer_list[:fibro_list.shape[0] + 300]\n",
    "\n",
    "X = np.concatenate((cancer_list, fibro_list), axis=0)\n",
    "y = np.concatenate((np.zeros(cancer_list.shape), np.ones(fibro_list.shape)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_315 (Conv2D)          (None, 158, 158, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_450 (Activation)  (None, 158, 158, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_316 (Conv2D)          (None, 156, 156, 32)      9248      \n",
      "_________________________________________________________________\n",
      "activation_451 (Activation)  (None, 156, 156, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_168 (MaxPoolin (None, 78, 78, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_317 (Conv2D)          (None, 76, 76, 48)        13872     \n",
      "_________________________________________________________________\n",
      "activation_452 (Activation)  (None, 76, 76, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_318 (Conv2D)          (None, 74, 74, 48)        20784     \n",
      "_________________________________________________________________\n",
      "activation_453 (Activation)  (None, 74, 74, 48)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_169 (MaxPoolin (None, 37, 37, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_319 (Conv2D)          (None, 33, 33, 64)        76864     \n",
      "_________________________________________________________________\n",
      "activation_454 (Activation)  (None, 33, 33, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_320 (Conv2D)          (None, 29, 29, 64)        102464    \n",
      "_________________________________________________________________\n",
      "activation_455 (Activation)  (None, 29, 29, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_170 (MaxPoolin (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_46 (Flatten)         (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dense_136 (Dense)            (None, 32)                401440    \n",
      "_________________________________________________________________\n",
      "activation_456 (Activation)  (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_91 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_137 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "activation_457 (Activation)  (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_92 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_138 (Dense)            (None, 1)                 33        \n",
      "_________________________________________________________________\n",
      "activation_458 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 626,657\n",
      "Trainable params: 626,657\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class TelegramTrainingLog(Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        msg = 'epoch: {}\\nloss: {}\\nacc: {}\\nval_loss: {}\\nval_acc: {}'.format(\n",
    "            epoch, logs.get('loss'), logs.get('acc'), logs.get('val_loss'), logs.get('val_acc'))\n",
    "        try:\n",
    "            telebot.sendMessage(user_id, msg)\n",
    "        except Exception:\n",
    "            None\n",
    "\n",
    "class TextTrainingLog(Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        msg = ' - epoch: {0}\\n  + loss   : {1:.6f}, acc:   {2:.6f}\\n  - val_loss: {3:.6f}, val_acc: {4:.6f}\\n'.format(\n",
    "            epoch, logs.get('loss'), logs.get('acc'), logs.get('val_loss'), logs.get('val_acc'))\n",
    "        with open('cnn.log') as f:\n",
    "            f.write(msg)\n",
    "\n",
    "\n",
    "def cnn_generator() -> Sequential:\n",
    "    model = Sequential()\n",
    "        \n",
    "    model.add(Conv2D(filters=32, kernel_size=(3, 3), strides=1, input_shape=(160, 160, 3)))\n",
    "    model.add(Activation('relu'))            \n",
    "    model.add(Conv2D(filters=32, kernel_size=(3, 3), strides=1))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(filters=48, kernel_size=(3, 3), strides=1))\n",
    "    model.add(Activation('relu'))    \n",
    "    model.add(Conv2D(filters=48, kernel_size=(3, 3), strides=1))\n",
    "    model.add(Activation('relu'))    \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(filters=64, kernel_size=(5, 5), strides=1))\n",
    "    model.add(Activation('relu'))    \n",
    "    model.add(Conv2D(filters=64, kernel_size=(5, 5), strides=1))\n",
    "    model.add(Activation('relu'))    \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))            \n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(32))\n",
    "    model.add(Activation('relu'))    \n",
    "    model.add(Dropout(0.3))        \n",
    "    \n",
    "    model.add(Dense(32))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    #sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    #model.compile(loss='binary_crossentropy', optimizer=sgd)\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='rmsprop',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    description = '32C3x2-48C3x2-64C5x2-F32-F32'\n",
    "    return description, model\n",
    "\n",
    "\n",
    "_, model = cnn_generator()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**KFold iteration #1**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3024 images belonging to 2 classes.\n",
      "Found 758 images belonging to 2 classes.\n",
      "INFO:tensorflow:Summary name conv2d_321/kernel:0 is illegal; using conv2d_321/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name conv2d_321/bias:0 is illegal; using conv2d_321/bias_0 instead.\n",
      "INFO:tensorflow:Summary name conv2d_322/kernel:0 is illegal; using conv2d_322/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name conv2d_322/bias:0 is illegal; using conv2d_322/bias_0 instead.\n",
      "INFO:tensorflow:Summary name conv2d_323/kernel:0 is illegal; using conv2d_323/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name conv2d_323/bias:0 is illegal; using conv2d_323/bias_0 instead.\n",
      "INFO:tensorflow:Summary name conv2d_324/kernel:0 is illegal; using conv2d_324/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name conv2d_324/bias:0 is illegal; using conv2d_324/bias_0 instead.\n",
      "INFO:tensorflow:Summary name conv2d_325/kernel:0 is illegal; using conv2d_325/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name conv2d_325/bias:0 is illegal; using conv2d_325/bias_0 instead.\n",
      "INFO:tensorflow:Summary name conv2d_326/kernel:0 is illegal; using conv2d_326/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name conv2d_326/bias:0 is illegal; using conv2d_326/bias_0 instead.\n",
      "INFO:tensorflow:Summary name dense_139/kernel:0 is illegal; using dense_139/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name dense_139/bias:0 is illegal; using dense_139/bias_0 instead.\n",
      "INFO:tensorflow:Summary name dense_140/kernel:0 is illegal; using dense_140/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name dense_140/bias:0 is illegal; using dense_140/bias_0 instead.\n",
      "INFO:tensorflow:Summary name dense_141/kernel:0 is illegal; using dense_141/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name dense_141/bias:0 is illegal; using dense_141/bias_0 instead.\n",
      "Epoch 1/80\n",
      "189/189 [==============================] - 994s - loss: 1.2489 - acc: 0.5093 - val_loss: 0.6894 - val_acc: 0.5399\n",
      "Epoch 2/80\n",
      "189/189 [==============================] - 973s - loss: 0.6946 - acc: 0.5364 - val_loss: 0.6894 - val_acc: 0.5364\n",
      "Epoch 3/80\n",
      "189/189 [==============================] - 965s - loss: 0.7410 - acc: 0.5413 - val_loss: 0.6884 - val_acc: 0.5431\n",
      "Epoch 4/80\n",
      "189/189 [==============================] - 962s - loss: 0.7044 - acc: 0.5380 - val_loss: 0.6849 - val_acc: 0.5445\n",
      "Epoch 5/80\n",
      "189/189 [==============================] - 962s - loss: 0.6950 - acc: 0.5394 - val_loss: 0.6854 - val_acc: 0.5606\n",
      "Epoch 6/80\n",
      "189/189 [==============================] - 958s - loss: 0.6929 - acc: 0.5394 - val_loss: 0.6905 - val_acc: 0.5337\n",
      "Epoch 7/80\n",
      "189/189 [==============================] - 956s - loss: 0.6923 - acc: 0.5367 - val_loss: 0.6904 - val_acc: 0.5323\n",
      "Epoch 8/80\n",
      "189/189 [==============================] - 952s - loss: 0.6921 - acc: 0.5390 - val_loss: 0.6901 - val_acc: 0.5418\n",
      "Epoch 9/80\n",
      "189/189 [==============================] - 953s - loss: 0.6932 - acc: 0.5400 - val_loss: 0.6914 - val_acc: 0.5243\n",
      "Epoch 10/80\n",
      "189/189 [==============================] - 955s - loss: 0.6918 - acc: 0.5394 - val_loss: 0.6881 - val_acc: 0.5499\n",
      "Epoch 11/80\n",
      "189/189 [==============================] - 956s - loss: 0.6917 - acc: 0.5476 - val_loss: 0.6889 - val_acc: 0.5418\n",
      "Epoch 12/80\n",
      "189/189 [==============================] - 955s - loss: 0.6929 - acc: 0.5400 - val_loss: 0.6870 - val_acc: 0.5526\n",
      "Epoch 13/80\n",
      "189/189 [==============================] - 955s - loss: 0.6910 - acc: 0.5417 - val_loss: 0.6888 - val_acc: 0.5364\n",
      "Epoch 14/80\n",
      "189/189 [==============================] - 989s - loss: 0.6950 - acc: 0.5397 - val_loss: 0.6849 - val_acc: 0.5499\n",
      "Epoch 15/80\n",
      "189/189 [==============================] - 957s - loss: 0.6930 - acc: 0.5377 - val_loss: 0.6869 - val_acc: 0.5404\n",
      "Epoch 16/80\n",
      "189/189 [==============================] - 952s - loss: 0.6904 - acc: 0.5394 - val_loss: 0.6875 - val_acc: 0.5404\n",
      "Epoch 17/80\n",
      "189/189 [==============================] - 954s - loss: 0.6902 - acc: 0.5509 - val_loss: 0.6849 - val_acc: 0.5479\n",
      "Epoch 18/80\n",
      "189/189 [==============================] - 952s - loss: 0.6900 - acc: 0.5440 - val_loss: 0.6816 - val_acc: 0.5714\n",
      "Epoch 19/80\n",
      "189/189 [==============================] - 952s - loss: 0.6888 - acc: 0.5532 - val_loss: 0.6869 - val_acc: 0.5445\n",
      "Epoch 20/80\n",
      "189/189 [==============================] - 952s - loss: 0.6893 - acc: 0.5542 - val_loss: 0.6806 - val_acc: 0.5687\n",
      "Epoch 21/80\n",
      "189/189 [==============================] - 956s - loss: 0.6890 - acc: 0.5549 - val_loss: 0.6844 - val_acc: 0.5593\n",
      "Epoch 22/80\n",
      "189/189 [==============================] - 951s - loss: 0.6880 - acc: 0.5546 - val_loss: 0.6886 - val_acc: 0.5458\n",
      "Epoch 23/80\n",
      "138/189 [====================>.........] - ETA: 237s - loss: 0.6901 - acc: 0.5494"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-78b727085c81>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtelegram_log\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensorboard_log\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             validation_steps=test_index.shape[0] // (batch_size))\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'log_cnn/{}_it{}.h5'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkfold_iteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/falcon/Workspace/cvtf/lib/python3.5/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     87\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_support_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/falcon/Workspace/cvtf/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_q_size, workers, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1105\u001b[0m                                         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m                                         \u001b[0mpickle_safe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle_safe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1107\u001b[0;31m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/falcon/Workspace/cvtf/lib/python3.5/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     87\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_support_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/falcon/Workspace/cvtf/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_q_size, workers, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1875\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   1876\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1877\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/falcon/Workspace/cvtf/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1619\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1620\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1621\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1622\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1623\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/falcon/Workspace/cvtf/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2101\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2102\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 2103\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   2104\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/falcon/Workspace/cvtf/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/falcon/Workspace/cvtf/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/falcon/Workspace/cvtf/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/falcon/Workspace/cvtf/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/falcon/Workspace/cvtf/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "kfold_iteration = 0\n",
    "for train_index, test_index in kfold.split(X, y):\n",
    "    kfold_iteration += 1\n",
    "    if kfold_iteration > 1:\n",
    "        break\n",
    "        \n",
    "    display(Markdown('**KFold iteration #{}**'.format(kfold_iteration)))\n",
    "\n",
    "    \"\"\"\n",
    "    cancer_trainlist = (X[train_index])[np.nonzero(1 - y[train_index])]\n",
    "    fibro_trainlist = (X[train_index])[np.nonzero(y[train_index])]\n",
    "    cancer_traindest = os.path.join(os.getcwd(), 'train', 'cancer')\n",
    "    fibro_traindest = os.path.join(os.getcwd(), 'train', 'fibro')        \n",
    "    classdir_prepare(cancer_trainlist, cancer_traindest, '[TRAIN] generating cancer')\n",
    "    classdir_prepare(fibro_trainlist, fibro_traindest, '[TRAIN] generating fibro ')\n",
    "\n",
    "    cancer_testlist = (X[test_index])[np.nonzero(1 - y[test_index])]\n",
    "    fibro_testlist = (X[test_index])[np.nonzero(y[test_index])]\n",
    "    cancer_testdest = os.path.join(os.getcwd(), 'test', 'cancer')\n",
    "    fibro_testdest = os.path.join(os.getcwd(), 'test', 'fibro')\n",
    "    classdir_prepare(cancer_testlist, cancer_testdest, '[TEST ] generating cancer')\n",
    "    classdir_prepare(fibro_testlist, fibro_testdest, '[TEST ] generating fibro ')\n",
    "    \"\"\"\n",
    "    \n",
    "    train_generator = train_data_generator.flow_from_directory(\n",
    "            directory=os.path.join(os.getcwd(), 'train'),\n",
    "            target_size=(160, 160),\n",
    "            classes=['cancer', 'fibro'],\n",
    "            class_mode='binary',\n",
    "            color_mode='rgb',\n",
    "            seed=random_seed,\n",
    "            batch_size=batch_size)\n",
    "    \n",
    "    test_generator = train_data_generator.flow_from_directory(\n",
    "            os.path.join(os.getcwd(), 'test'),\n",
    "            target_size=(160, 160),\n",
    "            classes=['cancer', 'fibro'],\n",
    "            class_mode='binary',\n",
    "            color_mode='rgb',\n",
    "            seed=random_seed,\n",
    "            batch_size=batch_size)\n",
    "    \n",
    "    desc, model = cnn_generator()\n",
    "    telegram_log = TelegramTrainingLog()\n",
    "    tensorboard_log = TensorBoard(log_dir='log_tb', \n",
    "                                  histogram_freq=1, \n",
    "                                  write_graph=True)\n",
    "    \n",
    "    checkpoint_fpath = 'log_cnn/' + desc + \\\n",
    "        str(kfold_iteration) + '_E{epoch:02d}_L{val_loss:.2f}_A{val_acc:.2f}.hdf5'\n",
    "        \n",
    "    checkpoint = ModelCheckpoint(\n",
    "        filepath=checkpoint_fpath,\n",
    "        monitor='val_loss',\n",
    "        verbose=0,\n",
    "        save_best_only=False,\n",
    "        save_weights_only=False,\n",
    "        mode='auto',\n",
    "        period=1\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        telebot.sendMessage(user_id, '{}\\n{}\\n{}{}\\n{}'.format('**********************************', \n",
    "                                                               desc,\n",
    "                                                               'Iteration: ', kfold_iteration,\n",
    "                                                               '**********************************'))\n",
    "    except Exception:\n",
    "        None\n",
    "                        \n",
    "    model.fit_generator(\n",
    "            generator=train_generator,\n",
    "            steps_per_epoch=train_index.shape[0] // (batch_size),\n",
    "            epochs=80,\n",
    "            callbacks=[telegram_log, checkpoint, tensorboard_log],\n",
    "            validation_data=test_generator,\n",
    "            validation_steps=test_index.shape[0] // (batch_size))\n",
    "        \n",
    "    model.save_weights('log_cnn/{}_it{}.h5'.format(desc, kfold_iteration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
